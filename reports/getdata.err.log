Traceback (most recent call last):
  File "/usr/local/lib/python3.9/dist-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/usr/local/lib/python3.9/dist-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/local/lib/python3.9/dist-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/usr/local/lib/python3.9/dist-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/dist-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/usr/local/lib/python3.9/dist-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/local/lib/python3.9/dist-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import orchest
import pandas as pd
from sklearn import datasets
# from ipynb.fs.full.PostgresSQLlocal import *
# from ipynb.fs.full.PostgresSQLcloud import *
# from ipynb.fs.full.MySQLlocal import *
# from ipynb.fs.full.SQLServer import *

# print(data_postgreSQL)
new_data_iris = pd.concat([data_postgreSQL,data_postgreSQLCloud,data_Mysql,data_SqlServer],axis=1)
new_data_iris['class'] = pd.Categorical(new_data_iris['class'])
new_data_iris["class"] = new_data_iris["class"].cat.codes
df_data = new_data_iris.values[:, 0:4]
df_target = new_data_iris.values[:, 4]
new_data_iris = new_data_iris.drop(columns=["class"])

# print(type(new_data_iris))

# df_datatarget = new_data_iris.drop(['class'],axis=1)
# df_data = new_data_iris
# print(df_datatarget)
# print(df_data)
# Explicitly cache the data in the "/data" directory since the
# kernel is running in a Docker container, which are stateless.
# The "/data" directory is a special directory managed by Orchest
# to allow data to be persisted and shared across pipelines and
# even projects.
print("Dowloading California housing data...")
data = datasets.fetch_california_housing(data_home="/data")
print(df_data)
print(df_target)
# Convert the data into a DataFrame.
# df_data = pd.DataFrame(data["data"], columns=data["feature_names"])
# df_target = pd.DataFrame(data["target"], columns=["MedHouseVal"])
# print(df_target)
# Output the housing data so the next steps can retrieve it.
print("Outputting converted housing data...")
orchest.output((df_data, df_target), name="data")
print("Success!")
------------------

[0;31m[0m
[0;31mModuleNotFoundError[0mTraceback (most recent call last)
[0;32m<ipython-input-16-36d54ddabe2e>[0m in [0;36m<module>[0;34m[0m
[0;32m----> 1[0;31m [0;32mimport[0m [0morchest[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0;32mimport[0m [0mpandas[0m [0;32mas[0m [0mpd[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;32mfrom[0m [0msklearn[0m [0;32mimport[0m [0mdatasets[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0;31m# from ipynb.fs.full.PostgresSQLlocal import *[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;31m# from ipynb.fs.full.PostgresSQLcloud import *[0m[0;34m[0m[0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'orchest'

[0;31m---------------------------------------------------------------------------[0;32m
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
"Open Examples" button below.
[0;31m---------------------------------------------------------------------------[0m

ModuleNotFoundError: No module named 'orchest'

